<!--
 * @Author: your name
 * @Date: 2021-06-17 20:09:14
 * @LastEditTime: 2021-07-14 21:51:36
 * @LastEditors: Please set LastEditors
 * @Description: In User Settings Edit
 * @FilePath: /Zero2OneBuildMachineLearningModel/README.md
-->
## 从零到一搭建经典的机器学习模型和深度学习模型
* 深度学习框架和机器学习库对机器学习模型进行非常高的封装，也使得不是该领域内的算法工程师和爱好者都能够快速训练和部署自己模型，但是对于一直长期从事机器学习相关算法的算法工程师，基础的日常熟练掌握非常重要，故有重新对相关的算法温故,采用pandas、numpy和python三方库(面向对象程序设计方案)实现这些模型

* 从零重写了scikit-learn 关于机器学习的经典算法函数
### 经典机器学习模型
#### 线性回归(Linear Regression) :rocket: **ToDo**
#### 逻辑回归(Logistic Regression)
#### 决策树(Decision Tree)
#### Kmeans 
#### SVM
#### SVD
#### PCA
#### random_forest
#### AdaBoost
#### GBDT
#### XGBoost
#### LightGBM
#### CatBoost
#### HMM
#### GMM
#### KNN
#### LDA
#### 贝叶斯(Bayesian model)
#### CRF

#### ......

#### 参考文献
[Machine_Learning_Code_Implementation](https://github.com/luwill/Machine_Learning_Code_Implementation)

[Scikit-learn](https://sklearn.apachecn.org/docs/examples/)

[Gensim](https://radimrehurek.com/gensim/auto_examples/index.html#documentation)

[手动推导经典机器学习模型](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI4ODY2NjYzMQ==&action=getalbum&album_id=1369989062744211457&scene=173&from_msgid=2247484471&from_itemidx=1&count=3&nolastread=1#wechat_redirect)
[阿泽笔记 关于决策树讲的很好](https://zhuanlan.zhihu.com/p/85731206)
### 深度学习模型
#### CNN
#### RNN
#### Transformer
#### Transformer-x
#### Attention(self-attention)
#### Seq2Seq
#### GNN
#### embeddding method
##### word2vec
##### fasttext
##### node2vec
#### ......
#### 参考文献
[PaddlePaddle](https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/index_cn.html)

[Transformes](https://huggingface.co/transformers/examples.html)

[Pytorch](https://pytorch.org/docs/stable/index.html)

[Tensorflow](https://tensorflow.google.cn/tutorials)

[best-of-ml-python](https://github.com/ml-tooling/best-of-ml-python)
[深度学习中的 Attention 机制总结与代码实现（2017-2021年）](https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&mid=2247526434&idx=2&sn=090d59b08e5786dbe18009ce796ee710&chksm=f9a11aadced693bbd3043ddcc8737e23da342f114f982b3ce1af3e110e0c8f118e8212ce1fd9&mpshare=1&scene=1&srcid=06181OYw3rMukzkeg44Hxfj4&sharer_sharetime=1623993035612&sharer_shareid=bb12138cbf7121360054152c6932a462&version=3.1.8.3015&platform=win#rd)

[xmu-xiaoma666/External-Attention-pytorch](https://github.com/xmu-xiaoma666/External-Attention-pytorch)

[Graph Neural Networks for Natural Language Processing: A Survey](https://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&mid=2247503451&idx=1&sn=0cfb45f050568f6f8fe681425f6ad078&chksm=eb53dac8dc2453dea1a32162267737c7d5458c6665d507fd1859b9e8d3909717cb51440fcb6f&mpshare=1&scene=1&srcid=0622ofqaYewpeU6XlieGPUgl&sharer_sharetime=1624325184664&sharer_shareid=bb12138cbf7121360054152c6932a462&version=3.1.8.3015&platform=win#rd)
[一文看尽深度学习中的各种注意力机制（1998-2020年）](https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&mid=2247527357&idx=2&sn=ae28db152ca827a294d87588be0cafaa&chksm=f9a11932ced69024cfd1229477af13496b41e327a68a3b9dd0199f8aeeb1891d06545940531f&mpshare=1&scene=1&srcid=06292DeC1OAJf0TDqkSsC5By&sharer_sharetime=1624943008429&sharer_shareid=bb12138cbf7121360054152c6932a462&version=3.1.8.3015&platform=win#rd)
[深度学习笔记3：手动搭建深度神经网络（DNN）](https://mp.weixin.qq.com/s?__biz=MzI4ODY2NjYzMQ==&mid=2247484171&idx=1&sn=bc35cddb7ca5976881cf1607f8caa2a1&chksm=ec3ba663db4c2f751d635dbcc863a01d7d0feae071ae19e720fbbdafd3e11fe7796a8f2573ca&scene=21#wechat_redirect)


### PTM(Pretrained Model)
* PTM模型大部分是基于上面基础深度学习网路，通过某种策略，搭建而成
#### BERT
#### GPT

